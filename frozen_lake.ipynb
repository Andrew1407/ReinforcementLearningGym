{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = 10_000\n",
    "MAX_STEPS_PER_EPISODE = 1000\n",
    "\n",
    "LEARNING_RATE = 1e-1\n",
    "DISCOUNT_RATE = .99\n",
    "MAX_EXPLORATION_RATE = 1\n",
    "MIN_EXPLORATION_RATE = 1e-2\n",
    "EXPLORATION_DECAY_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_rate = MAX_EXPLORATION_RATE\n",
    "\n",
    "env = gym.make('FrozenLake-v1', render_mode='ansi')\n",
    "\n",
    "action_space_size = env.action_space.n\n",
    "state_space_size = env.observation_space.n\n",
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_q_learning() -> list[float]:\n",
    "  global exploration_rate\n",
    "  episodes_reward: list[float] = list()\n",
    "  for episode in range(NUM_EPISODES):\n",
    "    state, observation = env.reset()\n",
    "    done = False\n",
    "    rewards_current_episode = 0\n",
    "    for step in range(MAX_STEPS_PER_EPISODE):\n",
    "      exploration_rate_threshold = np.random.uniform(0, 1)\n",
    "      if exploration_rate_threshold > exploration_rate:\n",
    "          action = np.argmax(q_table[state, :])\n",
    "      else:\n",
    "          action = env.action_space.sample()\n",
    "      new_state, reward, done, truncated, info = env.step(action)\n",
    "      q_table[state, action] = q_table[state, action] * (1 - LEARNING_RATE) + \\\n",
    "        LEARNING_RATE * (reward + DISCOUNT_RATE * np.max(q_table[new_state, :]))\n",
    "      state = new_state\n",
    "      rewards_current_episode += reward\n",
    "      if done: break\n",
    "\n",
    "    exploration_rate = MIN_EXPLORATION_RATE + (MAX_EXPLORATION_RATE - MIN_EXPLORATION_RATE) * np.exp(-EXPLORATION_DECAY_RATE * episode)\n",
    "    episodes_reward.append(rewards_current_episode)\n",
    "\n",
    "  return episodes_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game():\n",
    "  for episode in range(3):\n",
    "    state, observation = env.reset()\n",
    "    done = False\n",
    "    print('Episode', episode + 1)\n",
    "    time.sleep(1)\n",
    "    for step in range(MAX_STEPS_PER_EPISODE):\n",
    "      clear_output(wait=True)\n",
    "      print(env.render())\n",
    "      time.sleep(.3)\n",
    "\n",
    "      action = np.argmax(q_table[state, :])\n",
    "      new_state, reward, done, truncated, info = env.step(action)\n",
    "      if truncated:\n",
    "        print('The goal is failed')\n",
    "        break\n",
    "      \n",
    "      if done:\n",
    "        clear_output(wait=True)\n",
    "        print(env.render())\n",
    "        if reward == 1:\n",
    "          print('The goal is reached')\n",
    "        else:\n",
    "          print('The goal is failed')\n",
    "        time.sleep(3)\n",
    "        clear_output(wait=True)\n",
    "        break\n",
    "      state = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_score(episodes_reward: list[float]):\n",
    "  rewards_per_thousand_episodes = np.split(np.array(episodes_reward), NUM_EPISODES / 1000)\n",
    "  count = 1000\n",
    "  for r in rewards_per_thousand_episodes:\n",
    "    print(count, str(sum(r / 1000)))\n",
    "    count += 1000\n",
    "  print('\\nq_tabble:')\n",
    "  print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.04500000000000003\n",
      "2000 0.18500000000000014\n",
      "3000 0.4040000000000003\n",
      "4000 0.5810000000000004\n",
      "5000 0.7140000000000005\n",
      "6000 0.7260000000000005\n",
      "7000 0.7810000000000006\n",
      "8000 0.7630000000000006\n",
      "9000 0.7440000000000005\n",
      "10000 0.7300000000000005\n",
      "\n",
      "q_tabble:\n",
      "[[0.44480623 0.44410118 0.44397135 0.44388917]\n",
      " [0.29842049 0.22497557 0.31134099 0.42998582]\n",
      " [0.40460213 0.41073472 0.39858591 0.41879196]\n",
      " [0.26056392 0.31724715 0.21872503 0.41409896]\n",
      " [0.45458627 0.37479793 0.43156364 0.35981271]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.32835878 0.15183088 0.1750311  0.13329   ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.40084182 0.35989647 0.35737617 0.47854796]\n",
      " [0.39420656 0.53519484 0.38353808 0.4023924 ]\n",
      " [0.52739983 0.35525754 0.35967594 0.37845706]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.36341002 0.51800079 0.63148473 0.55408558]\n",
      " [0.71457    0.84612721 0.71651533 0.70365685]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "episodes_reward = run_q_learning()\n",
    "show_score(episodes_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "\n",
      "The goal is reached\n"
     ]
    }
   ],
   "source": [
    "run_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
